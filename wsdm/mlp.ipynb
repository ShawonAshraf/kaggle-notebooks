{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00007cff95d7f7974642a785aca248b0f26e60d3312fac...</td>\n",
       "      <td>vieš po Slovensky?</td>\n",
       "      <td>Áno, hovorím po slovensky. Ako vám môžem pomôcť?</td>\n",
       "      <td>Áno, veď som tu! Môžem ti pomôcť s otázkami al...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>Slovak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n",
       "      <td>You will be given a piece of news. Analyze it ...</td>\n",
       "      <td>Let's break down the news and analyze it accor...</td>\n",
       "      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003800d510e38803efba5ceaec122bc66408fe367b0be...</td>\n",
       "      <td>Dört basamaklı, rakamları birbirinden ve sıfır...</td>\n",
       "      <td>Bu soruyu çözmek için, verilen koşulları adım ...</td>\n",
       "      <td>Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00072026c68f5418ef2da238394e418ce72a534b9b22d5...</td>\n",
       "      <td>현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...</td>\n",
       "      <td>죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...</td>\n",
       "      <td>현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...</td>\n",
       "      <td>Please be boring</td>\n",
       "      <td>Alright, I'll be as boring as possible.\\n\\nTod...</td>\n",
       "      <td>Understood. Here is a straightforward, unadorn...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>reka-flash-20240722</td>\n",
       "      <td>grok-2-2024-08-13</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  00007cff95d7f7974642a785aca248b0f26e60d3312fac...   \n",
       "1  00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n",
       "2  0003800d510e38803efba5ceaec122bc66408fe367b0be...   \n",
       "3  00072026c68f5418ef2da238394e418ce72a534b9b22d5...   \n",
       "4  0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                 vieš po Slovensky?   \n",
       "1  You will be given a piece of news. Analyze it ...   \n",
       "2  Dört basamaklı, rakamları birbirinden ve sıfır...   \n",
       "3  현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...   \n",
       "4                                  Please be boring    \n",
       "\n",
       "                                          response_a  \\\n",
       "0   Áno, hovorím po slovensky. Ako vám môžem pomôcť?   \n",
       "1  Let's break down the news and analyze it accor...   \n",
       "2  Bu soruyu çözmek için, verilen koşulları adım ...   \n",
       "3  죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...   \n",
       "4  Alright, I'll be as boring as possible.\\n\\nTod...   \n",
       "\n",
       "                                          response_b   winner  \\\n",
       "0  Áno, veď som tu! Môžem ti pomôcť s otázkami al...  model_a   \n",
       "1  ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a   \n",
       "2  Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...  model_a   \n",
       "3  현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...  model_b   \n",
       "4  Understood. Here is a straightforward, unadorn...  model_a   \n",
       "\n",
       "               model_a                          model_b language  \n",
       "0           o1-preview               reka-core-20240904   Slovak  \n",
       "1       gemma-2-27b-it             gemini-1.5-flash-002  Russian  \n",
       "2   gpt-4-0125-preview       claude-3-5-sonnet-20240620  Turkish  \n",
       "3        gemma-2-2b-it  llama-3.1-nemotron-70b-instruct  English  \n",
       "4  reka-flash-20240722                grok-2-2024-08-13  English  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_main_df = pd.read_parquet(\"data/train.parquet\", engine=\"pyarrow\")\n",
    "train_main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vieš po Slovensky?</td>\n",
       "      <td>Áno, hovorím po slovensky. Ako vám môžem pomôcť?</td>\n",
       "      <td>Áno, veď som tu! Môžem ti pomôcť s otázkami al...</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You will be given a piece of news. Analyze it ...</td>\n",
       "      <td>Let's break down the news and analyze it accor...</td>\n",
       "      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dört basamaklı, rakamları birbirinden ve sıfır...</td>\n",
       "      <td>Bu soruyu çözmek için, verilen koşulları adım ...</td>\n",
       "      <td>Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...</td>\n",
       "      <td>죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...</td>\n",
       "      <td>현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please be boring</td>\n",
       "      <td>Alright, I'll be as boring as possible.\\n\\nTod...</td>\n",
       "      <td>Understood. Here is a straightforward, unadorn...</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                                 vieš po Slovensky?   \n",
       "1  You will be given a piece of news. Analyze it ...   \n",
       "2  Dört basamaklı, rakamları birbirinden ve sıfır...   \n",
       "3  현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...   \n",
       "4                                  Please be boring    \n",
       "\n",
       "                                          response_a  \\\n",
       "0   Áno, hovorím po slovensky. Ako vám môžem pomôcť?   \n",
       "1  Let's break down the news and analyze it accor...   \n",
       "2  Bu soruyu çözmek için, verilen koşulları adım ...   \n",
       "3  죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...   \n",
       "4  Alright, I'll be as boring as possible.\\n\\nTod...   \n",
       "\n",
       "                                          response_b   winner  \n",
       "0  Áno, veď som tu! Môžem ti pomôcť s otázkami al...  model_a  \n",
       "1  ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a  \n",
       "2  Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...  model_a  \n",
       "3  현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...  model_b  \n",
       "4  Understood. Here is a straightforward, unadorn...  model_a  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_columns = [\"prompt\", \"response_a\", \"response_b\", \"winner\"]\n",
    "train_df = train_main_df[required_columns]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_frame, validation_frame = train_test_split(train_df, random_state=2024, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list()\n",
    "for idx in range(len(train_frame)):\n",
    "    corpus.append(train_frame.iloc[idx][\"prompt\"])\n",
    "    corpus.append(train_frame.iloc[idx][\"response_a\"])\n",
    "    corpus.append(train_frame.iloc[idx][\"response_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108987it [00:05, 18903.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "vocabulary = set()\n",
    "token_lens = list()\n",
    "\n",
    "\n",
    "for idx, sentence in tqdm(enumerate(corpus)):\n",
    "    sentence = sentence.replace(\"\\n\", \" \")\n",
    "    tokens = sentence.split(\" \")\n",
    "    token_lens.append(len(tokens))\n",
    "    for token in tokens:\n",
    "        if token != \" \" or token != \"\":\n",
    "            vocabulary.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2061647"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx = {\n",
    "    word:idx for idx, word in enumerate(vocabulary)\n",
    "}\n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"vocabulary.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word_to_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51214"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.max(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': tensor([ 347465,  857093, 1080773,  ..., 2061648, 2061648, 2061648]),\n",
       " 'positive': tensor([1518887,  226638,  617963,  ..., 2061648, 2061648, 2061648]),\n",
       " 'negative': tensor([1198971,  602493,       0,  ..., 2061648, 2061648, 2061648])}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResponseDataset(Dataset):\n",
    "    def __init__(self, df, word_to_idx=word_to_idx, max_len=2048, pad_token=\"[PAD]\", oov_token=\"[OOV]\"):\n",
    "        self.df = df\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.max_len = max_len\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        \n",
    "        # add pad and oov token\n",
    "        self.word_to_idx[pad_token] = len(word_to_idx)\n",
    "        self.word_to_idx[oov_token] = len(word_to_idx)\n",
    "        \n",
    "        # label dict\n",
    "        self.label_dict = {\n",
    "            \"model_a\": 0,\n",
    "            \"model_b\": 1\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __encode(self, text):\n",
    "        encoded = torch.ones(self.max_len, dtype=torch.long) * \\\n",
    "            self.word_to_idx.get(self.pad_token)\n",
    "        \n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = text.split(\" \")\n",
    "        # limit to max len\n",
    "        tokens = tokens[:self.max_len]\n",
    "        \n",
    "        for idx, token in enumerate(tokens):\n",
    "            word_idx = self.word_to_idx.get(token, self.word_to_idx.get(self.oov_token))\n",
    "            encoded[idx] = word_idx\n",
    "            \n",
    "        return encoded\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        prompt = self.__encode(self.df.iloc[idx][\"prompt\"])\n",
    "        response_a = self.__encode(self.df.iloc[idx][\"response_a\"])\n",
    "        response_b = self.__encode(self.df.iloc[idx][\"response_b\"])\n",
    "        \n",
    "        label = self.df.iloc[idx][\"winner\"]\n",
    "        label = self.label_dict.get(label)\n",
    "        \n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"positive\": response_a if label == 0 else response_b,\n",
    "            \"negative\": response_b if label == 0 else response_a,\n",
    "        }\n",
    "        \n",
    "        \n",
    "ds = ResponseDataset(train_frame)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ResponseDataset(train_frame)\n",
    "valset = ResponseDataset(validation_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 128\n",
    "train_loader = DataLoader(trainset, batch_size=bs, shuffle=True) \n",
    "val_loader = DataLoader(valset, batch_size=bs, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': tensor([[1145386,  816394,  724135,  ..., 2061648, 2061648, 2061648],\n",
      "        [1562672, 2015393, 1812222,  ..., 2061648, 2061648, 2061648],\n",
      "        [ 106649, 1128516, 1582120,  ..., 2061648, 2061648, 2061648],\n",
      "        ...,\n",
      "        [1698758,  683475,  627324,  ..., 2061648, 2061648, 2061648],\n",
      "        [1094831, 1455095, 1177346,  ..., 2061648, 2061648, 2061648],\n",
      "        [ 802773,  801709,  877170,  ..., 2061648, 2061648, 2061648]]), 'positive': tensor([[ 231902,  632335, 1842316,  ..., 2061648, 2061648, 2061648],\n",
      "        [1345012,  612782,       0,  ..., 2061648, 2061648, 2061648],\n",
      "        [ 580417, 1464334,  875782,  ..., 2061648, 2061648, 2061648],\n",
      "        ...,\n",
      "        [ 138431, 1162813,   69453,  ..., 2061648, 2061648, 2061648],\n",
      "        [ 378806, 1045391,  664294,  ..., 2061648, 2061648, 2061648],\n",
      "        [ 337284, 1613688,       0,  ..., 2061648, 2061648, 2061648]]), 'negative': tensor([[ 231902,  632335, 1842316,  ..., 2061648, 2061648, 2061648],\n",
      "        [1772813,  545400,  530979,  ..., 2061648, 2061648, 2061648],\n",
      "        [1314696, 1673870, 1317225,  ..., 2061648, 2061648, 2061648],\n",
      "        ...,\n",
      "        [ 106462, 1116790, 1126564,  ..., 2061648, 2061648, 2061648],\n",
      "        [ 378806, 1045391,  664294,  ..., 2061648, 2061648, 2061648],\n",
      "        [ 280048,  798361,   10191,  ..., 2061648, 2061648, 2061648]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0841)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning.pytorch as L\n",
    "import torch.optim as optim\n",
    "\n",
    "class Classifier(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,\n",
    "        embedding_size,\n",
    "        dropout,\n",
    "        lr,\n",
    "        batch_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # modules\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.embedding_size,\n",
    "            self.embedding_dim\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.hidden_dim, hidden_dim // 2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # criterion \n",
    "        self.criterion = nn.TripletMarginLoss()\n",
    "        \n",
    "    def forward(self, prompt, positive, negative):\n",
    "        prompt = self.embedding(prompt)\n",
    "        positive = self.embedding(positive)\n",
    "        negative = self.embedding(negative)\n",
    "        \n",
    "        prompt = self.mlp(prompt)\n",
    "        positive = self.mlp(positive)\n",
    "        negative = self.mlp(negative)\n",
    "        \n",
    "        return prompt, positive, negative\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# model = Classifier(2048, 256, 512, len(word_to_idx) + 2, 0.1, 1e-3, bs)\n",
    "# with torch.no_grad():\n",
    "#     for batch in train_loader:\n",
    "#         out = model(**batch)\n",
    "#         p, a, b = out\n",
    "        \n",
    "#         loss = F.triplet_margin_loss(p, a, b)\n",
    "#         print(loss)\n",
    "        \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
