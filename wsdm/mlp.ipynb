{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_main_df = pd.read_parquet(\"data/train.parquet\", engine=\"pyarrow\")\n",
    "train_main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = [\"prompt\", \"response_a\", \"response_b\", \"winner\"]\n",
    "train_df = train_main_df[required_columns]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_frame, validation_frame = train_test_split(train_df, random_state=2024, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list()\n",
    "for idx in range(len(train_frame)):\n",
    "    corpus.append(train_frame.iloc[idx][\"prompt\"])\n",
    "    corpus.append(train_frame.iloc[idx][\"response_a\"])\n",
    "    corpus.append(train_frame.iloc[idx][\"response_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "vocabulary = set()\n",
    "token_lens = list()\n",
    "\n",
    "\n",
    "for idx, sentence in tqdm(enumerate(corpus)):\n",
    "    sentence = sentence.replace(\"\\n\", \" \")\n",
    "    tokens = sentence.split(\" \")\n",
    "    token_lens.append(len(tokens))\n",
    "    for token in tokens:\n",
    "        if token != \" \" or token != \"\":\n",
    "            vocabulary.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {\n",
    "    word:idx for idx, word in enumerate(vocabulary)\n",
    "}\n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"vocabulary.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word_to_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.max(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResponseDataset(Dataset):\n",
    "    def __init__(self, df, word_to_idx=word_to_idx, max_len=2048, pad_token=\"[PAD]\", oov_token=\"[OOV]\"):\n",
    "        self.df = df\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.max_len = max_len\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        \n",
    "        # add pad and oov token\n",
    "        self.word_to_idx[pad_token] = len(word_to_idx)\n",
    "        self.word_to_idx[oov_token] = len(word_to_idx)\n",
    "        \n",
    "        # label dict\n",
    "        self.label_dict = {\n",
    "            \"model_a\": 0,\n",
    "            \"model_b\": 1\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __encode(self, text):\n",
    "        encoded = torch.ones(self.max_len, dtype=torch.long) * \\\n",
    "            self.word_to_idx.get(self.pad_token)\n",
    "        \n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = text.split(\" \")\n",
    "        # limit to max len\n",
    "        tokens = tokens[:self.max_len]\n",
    "        \n",
    "        for idx, token in enumerate(tokens):\n",
    "            word_idx = self.word_to_idx.get(token, self.word_to_idx.get(self.oov_token))\n",
    "            encoded[idx] = word_idx\n",
    "            \n",
    "        return encoded\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        prompt = self.__encode(self.df.iloc[idx][\"prompt\"])\n",
    "        response_a = self.__encode(self.df.iloc[idx][\"response_a\"])\n",
    "        response_b = self.__encode(self.df.iloc[idx][\"response_b\"])\n",
    "        \n",
    "        label = self.df.iloc[idx][\"winner\"]\n",
    "        label = self.label_dict.get(label)\n",
    "        \n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"positive\": response_a if label == 0 else response_b,\n",
    "            \"negative\": response_b if label == 0 else response_a,\n",
    "        }\n",
    "        \n",
    "        \n",
    "ds = ResponseDataset(train_frame)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ResponseDataset(train_frame)\n",
    "valset = ResponseDataset(validation_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 128\n",
    "train_loader = DataLoader(trainset, batch_size=bs, shuffle=True) \n",
    "val_loader = DataLoader(valset, batch_size=bs, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning.pytorch as L\n",
    "import torch.optim as optim\n",
    "\n",
    "class Classifier(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,\n",
    "        embedding_size,\n",
    "        dropout,\n",
    "        lr,\n",
    "        batch_size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # modules\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.embedding_size,\n",
    "            self.embedding_dim\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.hidden_dim, hidden_dim // 2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # criterion \n",
    "        self.criterion = nn.TripletMarginLoss()\n",
    "        \n",
    "    def forward(self, prompt, positive, negative):\n",
    "        prompt = self.embedding(prompt)\n",
    "        positive = self.embedding(positive)\n",
    "        negative = self.embedding(negative)\n",
    "        \n",
    "        prompt = self.mlp(prompt)\n",
    "        positive = self.mlp(positive)\n",
    "        negative = self.mlp(negative)\n",
    "        \n",
    "        return prompt, positive, negative\n",
    "    \n",
    "    def compute_loss(self, batch):\n",
    "        prompt, positive, negative = self(**batch)\n",
    "        loss = self.criterion(prompt, positive, negative)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # TODO: later\n",
    "    def compute_metrics(self, batch):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(lr=self.lr, params=self.parameters())\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch)\n",
    "        self.log(\"loss/train\", loss, prog_bar=True,\n",
    "                 batch_size=self.batch_size)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"log\": {\n",
    "                \"loss/train\": loss\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch)\n",
    "        self.log(\"loss/validation\", loss, prog_bar=True,\n",
    "                 batch_size=self.batch_size)\n",
    "        return {\n",
    "            \"val_loss\": loss,\n",
    "            \"log\": {\n",
    "                \"loss/validation\": loss\n",
    "            }\n",
    "        }\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# model = Classifier(2048, 256, 512, len(word_to_idx) + 2, 0.1, 1e-3, bs)\n",
    "# with torch.no_grad():\n",
    "#     for batch in train_loader:\n",
    "#         out = model(**batch)\n",
    "#         p, a, b = out\n",
    "        \n",
    "#         loss = F.triplet_margin_loss(p, a, b)\n",
    "#         print(loss)\n",
    "        \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "\n",
    "model = Classifier(2048, 256, 512, len(word_to_idx) + 2, 0.1, 1e-3, bs)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=2,\n",
    "    devices=1,\n",
    "    accelerator=\"gpu\",\n",
    "    log_every_n_steps=50\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
